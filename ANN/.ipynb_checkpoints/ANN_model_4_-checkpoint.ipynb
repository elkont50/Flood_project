{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "from pandas._libs.tslibs import timestamps\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import pymysql\n",
    "from  sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error,confusion_matrix, accuracy_score\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "Axes3D = Axes3D  # pycharm auto import\n",
    "#Import the Keras libraries and packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense,Dropout\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import seaborn as sns\n",
    "from pandas.tseries.holiday import USFederalHolidayCalendar\n",
    "from pandas.tseries.offsets import CustomBusinessDay\n",
    "us_bd = CustomBusinessDay(calendar=USFederalHolidayCalendar())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydb=pymysql.connect(host='localhost',port=int(3306),user='root',passwd='',db='sensor_data') \n",
    "#waterlevel range 1\n",
    "query1 = \"Select cast(timestamp as char) as Date, cast(thingName as char) as waterLevel, ROW_NUMBER() OVER (ORDER BY id) row_num , cast(value as char) as water_value  FROM sensor_data WHERE thingName ='NIVÅ015'  AND data_type='waterLevelMmAdjustedRH2000';\"\n",
    "df1 = pd.read_sql(query1,mydb)\n",
    "#print(df1)\n",
    "#sea level\n",
    "query2 = \"Select cast(thingName as char) as seaLevel,ROW_NUMBER() OVER (ORDER BY id) row_num, cast(value as char) as sea_value FROM sensor_data WHERE thingName BETWEEN 'NIVÅ015' AND 'NIVÅ016' AND data_type='waterLevelMmAdjustedRH2000';\"\n",
    "df2 = pd.read_sql(query2,mydb)\n",
    "#print(df2)\n",
    "#ground water\n",
    "query3 = \"Select  cast(thingName as char) as groundLevel, ROW_NUMBER() OVER (ORDER BY id) row_num, cast(value as char) as ground_value,smhi_rain  FROM sensor_data WHERE data_type='waterLevel';\"\n",
    "df3 = pd.read_sql(query3,mydb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0      2021-05-28 23:54:16\n",
      "1      2021-05-28 22:57:20\n",
      "2      2021-05-28 22:01:58\n",
      "3      2021-05-28 20:50:48\n",
      "4      2021-05-28 19:50:53\n",
      "               ...        \n",
      "1617   2021-08-04 06:01:10\n",
      "1618   2021-08-04 05:01:06\n",
      "1619   2021-08-04 03:51:11\n",
      "1620   2021-08-04 01:59:58\n",
      "1621   2021-08-04 01:00:44\n",
      "Name: Date, Length: 1622, dtype: datetime64[ns]\n",
      "      row_num waterLevel water_value\n",
      "0           1    Nivå015         115\n",
      "1           2    Nivå015         144\n",
      "2           3    Nivå015         110\n",
      "3           4    Nivå015         140\n",
      "4           5    Nivå015         123\n",
      "...       ...        ...         ...\n",
      "1617     1618    Nivå015         168\n",
      "1618     1619    Nivå015         172\n",
      "1619     1620    Nivå015         161\n",
      "1620     1621    Nivå015         165\n",
      "1621     1622    Nivå015         193\n",
      "\n",
      "[1622 rows x 3 columns]\n",
      "      row_num seaLevel sea_value\n",
      "0           1  Nivå016        79\n",
      "1           2  Nivå016       103\n",
      "2           3  Nivå016       111\n",
      "3           4  Nivå016       134\n",
      "4           5  Nivå016       150\n",
      "...       ...      ...       ...\n",
      "3217     3218  Nivå015       168\n",
      "3218     3219  Nivå015       172\n",
      "3219     3220  Nivå015       161\n",
      "3220     3221  Nivå015       165\n",
      "3221     3222  Nivå015       193\n",
      "\n",
      "[3222 rows x 3 columns]\n",
      "        row_num groundLevel ground_value smhi_rain\n",
      "0             1      GND003      2.79825       8.5\n",
      "1             2      GND003      2.79825       8.5\n",
      "2             3      GND003      2.79825       8.5\n",
      "3             4      GND003      2.79825       8.5\n",
      "4             5      GND003      2.79825       8.5\n",
      "...         ...         ...          ...       ...\n",
      "207669   207670      GND017    0.0273851       0.0\n",
      "207670   207671      GND017    0.0273851       0.0\n",
      "207671   207672      GND017    0.0273851       0.0\n",
      "207672   207673      GND017    0.0273851       0.0\n",
      "207673   207674      GND017    0.0273851       0.0\n",
      "\n",
      "[207674 rows x 4 columns]\n",
      "      row_num groundLevel ground_value smhi_rain waterLevel water_value  \\\n",
      "0           1      GND003      2.79825       8.5    Nivå015         115   \n",
      "1           2      GND003      2.79825       8.5    Nivå015         144   \n",
      "2           3      GND003      2.79825       8.5    Nivå015         110   \n",
      "3           4      GND003      2.79825       8.5    Nivå015         140   \n",
      "4           5      GND003      2.79825       8.5    Nivå015         123   \n",
      "...       ...         ...          ...       ...        ...         ...   \n",
      "1617     1618      GND002      4.87205       3.1    Nivå015         168   \n",
      "1618     1619      GND002       4.8733       3.1    Nivå015         172   \n",
      "1619     1620      GND002       4.8733       3.1    Nivå015         161   \n",
      "1620     1621      GND002      4.87454       3.1    Nivå015         165   \n",
      "1621     1622      GND002      4.87703       3.1    Nivå015         193   \n",
      "\n",
      "     seaLevel sea_value  \n",
      "0     Nivå016        79  \n",
      "1     Nivå016       103  \n",
      "2     Nivå016       111  \n",
      "3     Nivå016       134  \n",
      "4     Nivå016       150  \n",
      "...       ...       ...  \n",
      "1617  Nivå015       293  \n",
      "1618  Nivå015       272  \n",
      "1619  Nivå015       302  \n",
      "1620  Nivå015       302  \n",
      "1621  Nivå015       282  \n",
      "\n",
      "[1622 rows x 8 columns]\n",
      "[['115' '8.5' '79' '2.79825']\n",
      " ['144' '8.5' '103' '2.79825']\n",
      " ['110' '8.5' '111' '2.79825']\n",
      " ...\n",
      " ['161' '3.1' '302' '4.8733']\n",
      " ['165' '3.1' '302' '4.87454']\n",
      " ['193' '3.1' '282' '4.87703']]\n"
     ]
    }
   ],
   "source": [
    "#Separate dates for future plotting\n",
    "df1[\"Date\"] = pd.to_datetime(df1[\"Date\"])\n",
    "train_dates = df1[\"Date\"] \n",
    "\n",
    "print(train_dates)\n",
    "#print(train_dates.tail(15))#Check last few dates. \n",
    " \n",
    "df1_1=pd.DataFrame(df1[[\"row_num\",\"waterLevel\",\"water_value\"]])\n",
    "df2_2=pd.DataFrame(df2[[\"row_num\",\"seaLevel\",\"sea_value\"]])\n",
    "df3_3=pd.DataFrame(df3[[\"row_num\",\"groundLevel\",\"ground_value\",\"smhi_rain\"]])\n",
    "#print reading result\n",
    "print(df1_1)\n",
    "print(df2_2)\n",
    "print(df3_3)\n",
    "# concatniting data\n",
    "#dataframe=[df3_3,df2_2,df1_1]\n",
    "#df1.merge(df2_2,how='left', left_on='Column1', right_on='ColumnA')\n",
    "df=pd.merge(df3_3,df1_1, on='row_num')\n",
    "df_last=pd.merge(df,df2_2, on='row_num')\n",
    "print(df_last)\n",
    "\n",
    " # x, y with sklearn convert to nump.ndarray\n",
    "df_last = df_last[[\"water_value\",\"smhi_rain\",\"sea_value\",\"ground_value\"]].to_numpy()# here we have 4 variables for multiple regression. \n",
    "#y = df_last[[\"water_value\"]].to_numpy() \n",
    "#df_last=pd.merge(x,y, on=\"row_num\")\n",
    "    #print(x)\n",
    "print(df_last)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize the dataset\n",
    "scaler = StandardScaler()\n",
    "scaler=scaler.fit(df_last)\n",
    "df_x=scaler.transform(df_last)\n",
    "# splitting the data\n",
    "#x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
    "#print(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[ 5.17003504e-02  4.93826924e-01 -1.16507563e-01 -5.22033641e-01]\n",
      "  [ 3.37232942e-01  4.93826924e-01  1.29367229e-01 -5.22033641e-01]\n",
      "  [ 2.47059324e-03  4.93826924e-01  2.11325493e-01 -5.22033641e-01]\n",
      "  ...\n",
      "  [-5.09518881e-01  4.93826924e-01  2.52304625e-01 -5.22033641e-01]\n",
      "  [-5.88286493e-01  4.93826924e-01  5.49403332e-01 -5.22033641e-01]\n",
      "  [-7.62970182e-02  4.93826924e-01  2.01080710e-01 -5.22033641e-01]]\n",
      "\n",
      " [[ 3.37232942e-01  4.93826924e-01  1.29367229e-01 -5.22033641e-01]\n",
      "  [ 2.47059324e-03  4.93826924e-01  2.11325493e-01 -5.22033641e-01]\n",
      "  [ 2.97849136e-01  4.93826924e-01  4.46955502e-01 -5.22033641e-01]\n",
      "  ...\n",
      "  [-5.88286493e-01  4.93826924e-01  5.49403332e-01 -5.22033641e-01]\n",
      "  [-7.62970182e-02  4.93826924e-01  2.01080710e-01 -5.22033641e-01]\n",
      "  [ 2.19081525e-01  4.93826924e-01  5.08424200e-01 -5.22033641e-01]]\n",
      "\n",
      " [[ 2.47059324e-03  4.93826924e-01  2.11325493e-01 -5.22033641e-01]\n",
      "  [ 2.97849136e-01  4.93826924e-01  4.46955502e-01 -5.22033641e-01]\n",
      "  [ 1.30467962e-01  4.93826924e-01  6.10872030e-01 -5.22033641e-01]\n",
      "  ...\n",
      "  [-7.62970182e-02  4.93826924e-01  2.01080710e-01 -5.22033641e-01]\n",
      "  [ 2.19081525e-01  4.93826924e-01  5.08424200e-01 -5.22033641e-01]\n",
      "  [ 1.79697719e-01  4.93826924e-01  3.34262889e-01 -5.22033641e-01]]\n",
      "\n",
      " ...\n",
      "\n",
      " [[ 1.34151999e+00 -2.02500097e+00  2.31150601e+00  3.16612982e-01]\n",
      "  [ 1.45967141e+00 -2.02500097e+00  3.30524996e+00  3.17115948e-01]\n",
      "  [ 1.40059570e+00 -2.02500097e+00  2.02465208e+00  3.17115948e-01]\n",
      "  ...\n",
      "  [ 8.09838611e-01 -2.02500097e+00  1.98367295e+00  3.19135923e-01]\n",
      "  [ 5.73535776e-01 -2.02500097e+00  2.07587600e+00  3.19135923e-01]\n",
      "  [ 6.12919582e-01 -2.02500097e+00  1.86073556e+00  3.19642945e-01]]\n",
      "\n",
      " [[ 1.45967141e+00 -2.02500097e+00  3.30524996e+00  3.17115948e-01]\n",
      "  [ 1.40059570e+00 -2.02500097e+00  2.02465208e+00  3.17115948e-01]\n",
      "  [ 1.34151999e+00 -2.02500097e+00  2.09636556e+00  3.17115948e-01]\n",
      "  ...\n",
      "  [ 5.73535776e-01 -2.02500097e+00  2.07587600e+00  3.19135923e-01]\n",
      "  [ 6.12919582e-01 -2.02500097e+00  1.86073556e+00  3.19642945e-01]\n",
      "  [ 5.04614116e-01 -2.02500097e+00  2.16807905e+00  3.19642945e-01]]\n",
      "\n",
      " [[ 1.40059570e+00 -2.02500097e+00  2.02465208e+00  3.17115948e-01]\n",
      "  [ 1.34151999e+00 -2.02500097e+00  2.09636556e+00  3.17115948e-01]\n",
      "  [ 1.45967141e+00 -2.02500097e+00  2.30126122e+00  3.17115948e-01]\n",
      "  ...\n",
      "  [ 6.12919582e-01 -2.02500097e+00  1.86073556e+00  3.19642945e-01]\n",
      "  [ 5.04614116e-01 -2.02500097e+00  2.16807905e+00  3.19642945e-01]\n",
      "  [ 5.43997922e-01 -2.02500097e+00  2.16807905e+00  3.20145911e-01]]]\n",
      "[[0.21908152]\n",
      " [0.17969772]\n",
      " [0.66214934]\n",
      " ...\n",
      " [0.50461412]\n",
      " [0.54399792]\n",
      " [0.81968456]]\n",
      "x_train shape == (1607, 15, 4).\n",
      "y_train shape == (1607, 1).\n"
     ]
    }
   ],
   "source": [
    "#As required for LSTM networks, we require to reshape an input data into n_samples x timesteps x n_features. \n",
    "#In this example, the n_features is 4. We will make timesteps = 15 (past days data used for training). \n",
    "\n",
    "#Empty lists to be populated using formatted training data\n",
    "x_train = []\n",
    "y_train = []\n",
    "\n",
    "n_future = 1   # Number of days we want to look into the future based on the past days.\n",
    "n_past = 15  # Number of past days we want to use to predict the future.\n",
    "\n",
    "#Reformat input data into a shape: (n_samples x timesteps x n_features)\n",
    "#the df_x has a shape (3208, 4)\n",
    "#3208 refers to the number of data points and 4 refers to the columns (multi-variables).\n",
    "for i in range(n_past, len(df_x) - n_future +1):\n",
    "    x_train.append(df_x[i - n_past:i, 0:df_x.shape[1]])\n",
    "    y_train.append(df_x[i + n_future - 1:i + n_future, 0])\n",
    "\n",
    "x_train,y_train = np.array(x_train), np.array(y_train)\n",
    "\n",
    "print(x_train)\n",
    "print(y_train)\n",
    "print('x_train shape == {}.'.format(x_train.shape))\n",
    "print('y_train shape == {}.'.format(y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 15, 64)            17664     \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                12416     \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 30,113\n",
      "Trainable params: 30,113\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# define the Autoencoder model\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, activation='relu', input_shape=(x_train.shape[1], x_train.shape[2]), return_sequences=True))\n",
    "model.add(LSTM(32, activation='relu', return_sequences=False))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y_train.shape[1]))\n",
    "\n",
    "model.compile(optimizer='adam', loss='mse',metrics=['mean_squared_error', 'mean_absolute_error', 'mean_absolute_percentage_error'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "history = model.fit(x_train, y_train, epochs=5, batch_size=16, validation_split=0.1, verbose=1)\n",
    "\n",
    "plt.plot(history.history['loss'], label='Training loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation loss')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot metrics\n",
    "plt.plot(history.history['mean_squared_error'])\n",
    "plt.plot(history.history['mean_absolute_error'])\n",
    "plt.plot(history.history['mean_absolute_percentage_error'])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_future=7\n",
    "#n_past = 16\n",
    "#n_days_for_prediction=15\n",
    "#print(train_dates)\n",
    "#train_dates=pd.to_datetime(pd.Series(df1[\"Date\"]))\n",
    "#print(train_dates)\n",
    "#list(train_dates)[-1]\n",
    "forecast_period_dates = pd.date_range(start=datetime.now(), periods=n_future, freq='1D').tolist()\n",
    "#print(forecast_period_dates)\n",
    "#predict the next 7 days\n",
    "#print(x_train)\n",
    "forecast = model.predict(x_train[-n_future:])\n",
    "#print(forecast)\n",
    "forecast_copies =np.repeat(forecast, df_last.shape[1],axis=-1)\n",
    "y_pred_future = scaler.inverse_transform(forecast_copies)[:,0]\n",
    "#print(forecast_copies)\n",
    "#print(y_pred_future)\n",
    "# Convert timestamp to date\n",
    "forecast_dates = []\n",
    "for time_i in forecast_period_dates:\n",
    "    forecast_dates.append(time_i.date())\n",
    "df_forecast = pd.DataFrame({'Date':np.array(forecast_dates), 'Water_Level_last':y_pred_future})\n",
    "df_forecast[\"Date\"]=pd.to_datetime(df_forecast[\"Date\"])\n",
    "print(df_forecast)\n",
    "\n",
    "original = df1[[\"Date\",\"water_value\"]]\n",
    "original = original.tail(7)\n",
    "print(original)\n",
    "#original[\"Date\"]=df1[\"Date\"]\n",
    "#original = original.loc[original[\"Date\"] >= '2021-8-4']\n",
    "#print(original)\n",
    "#sns.set(rc={'figure.figsize':(8,8)})\n",
    "#sns.lineplot(original[\"Date\"], original[\"water_value\"])\n",
    "sns.lineplot(df_forecast[\"Date\"], df_forecast[\"Water_Level_last\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test values\n",
    "predicted_waterLevel = df_forecast[\"Water_Level_last\"] \n",
    "print(\"Water Level for next 7 days :\\n\",df_forecast) \n",
    "for i in predicted_waterLevel:\n",
    "    if(i > 900): \n",
    "         print(\"Will flood soon\") \n",
    "    else:\n",
    "         print(\"Water level is OK\") \n",
    "dir='C:\\\\Users\\\\alha1207\\\\ANN\\\\output\\\\'\n",
    "filename ='ANN_model_4.sav' \n",
    "joblib.dump(predicted_waterLevel, dir + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## database cloding \n",
    "mydb.close() #close the connection\n",
    "print(\"Database closed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

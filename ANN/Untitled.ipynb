{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import pandas as pd\n",
    "from pandas._libs.tslibs import timestamps\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import pymysql\n",
    "from  sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import r2_score\n",
    "from datetime import datetime\n",
    "import joblib\n",
    "from sklearn.metrics import mean_squared_error,confusion_matrix, accuracy_score\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "Axes3D = Axes3D  # pycharm auto import\n",
    "#Import the Keras libraries and packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    mydb = pymysql.connect(host=\"localhost\",port=int(3306), database = 'sensor_data',user=\"root\", passwd=\"\",use_pure=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#waterlevel range 1\n",
    "    query1 = \"Select cast(thingName as char) as waterLevel, ROW_NUMBER() OVER (ORDER BY id) row_num , cast(value as char) as water_value  FROM sensor_data WHERE thingName BETWEEN 'NIVÅ001' AND 'NIVÅ010' AND data_type='waterLevelMmAdjustedRH2000' ;\"\n",
    "    df1 = pd.read_sql(query1,mydb)\n",
    "    #print(df1)\n",
    "    #sea level\n",
    "    query2 = \"Select cast(thingName as char) as seaLevel,ROW_NUMBER() OVER (ORDER BY id) row_num, cast(value as char) as sea_value FROM sensor_data WHERE thingName BETWEEN 'NIVÅ015' AND 'NIVÅ016' AND data_type='waterLevelMmAdjustedRH2000' ;\"\n",
    "    df2 = pd.read_sql(query2,mydb)\n",
    "    #print(df2)\n",
    "    #ground water\n",
    "    query3 = \"Select  cast(thingName as char) as groundLevel, ROW_NUMBER() OVER (ORDER BY id) row_num, cast(value as char) as ground_value,smhi_rain  FROM sensor_data WHERE data_type='waterLevel' ;\"\n",
    "    df3 = pd.read_sql(query3,mydb)\n",
    "    #print(df3)\n",
    "    #print(df1)\n",
    "    #print(df2)\n",
    "    #print(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read values\n",
    "    df1_1=pd.DataFrame(df1[[\"row_num\",\"waterLevel\",\"water_value\"]])\n",
    "    df2_2=pd.DataFrame(df2[[\"row_num\",\"seaLevel\",\"sea_value\"]])\n",
    "    df3_3=pd.DataFrame(df3[[\"row_num\",\"groundLevel\",\"ground_value\",\"smhi_rain\"]])\n",
    "    #print reading result\n",
    "    #print(df1_1)\n",
    "    #print(df2_2)\n",
    "    #print(df3_3)\n",
    "    # concatniting data\n",
    "    #dataframe=[df3_3,df2_2,df1_1]\n",
    "    #df1.merge(df2_2,how='left', left_on='Column1', right_on='ColumnA')\n",
    "    df=pd.merge(df3_3,df1_1, on='row_num')\n",
    "    df_last=pd.merge(df,df2_2, on='row_num')\n",
    "    #print(df_last)\n",
    "    # x, y with sklearn convert to nump.ndarray\n",
    "    x = df_last[[\"smhi_rain\",\"sea_value\",\"ground_value\"]].to_numpy()# here we have 3 variables for multiple regression. \n",
    "    y = df_last[[\"water_value\"]].to_numpy() \n",
    "    print(x)\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change the data type to avoid array problem\n",
    "    x = x.astype(np.float64,copy=False)\n",
    "    y = y.astype(np.float64,copy=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 0)\n",
    "    #print(x_train)\n",
    "    #print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # Initialize the Artificial Neural Network\n",
    "    classifier = Sequential()\n",
    "    #Add the input layer and the first hidden layer\n",
    "    classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu', input_dim = 3))\n",
    "    #Add the second hidden layer\n",
    "    classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'relu'))\n",
    "    #Add the output layer\n",
    "    classifier.add(Dense(output_dim = 6, init = 'uniform', activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Train the ANN\n",
    "    #Compile the ANN\n",
    "    classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "    #Fit the ANN to the Training set\n",
    "    classifier.fit(x_train, y_train, batch_size = 10, nb_epoch = 100)\n",
    "    #Predict the Test Set Results-\n",
    "    y_pred = classifier.predict(x_test)\n",
    "    y_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Make the Confusion Matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    accuracy_score(y_test,y_pred)\n",
    "\n",
    "    # print(y_pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # test values \n",
    "    #\n",
    "    values=[[8.0,40,2.79]]\n",
    "    ##\n",
    "    predicted_waterLevel = classifier.predict(values)\n",
    "    print(predicted_waterLevel)\n",
    "    if(predicted_waterLevel > 1200):\n",
    "        print(\"Will flood soon\")\n",
    "    else:\n",
    "        print(\"Water level is OK\")\n",
    "    dir='C:\\\\wamp64\\\\www\\\\Flood_project\\\\ANN\\\\output\\\\'\n",
    "    filename ='ANN_model_1.sav'\n",
    "    joblib.dump(classifier, dir + filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "   #evaluation the model\n",
    "    #r2_score(y_test,y_pred)\n",
    "    #plot resut\n",
    "    #plt.figure(figsize=(15,10))\n",
    "    #plt.scatter(y_test,y_pred)\n",
    "    #plt.xlabel(\"Acual\")\n",
    "    #plt.ylabel(\"predicted\")\n",
    "    #plt.title(\"Acual vs. Predicted\")\n",
    "    #plt.show()\n",
    "    #predict values\n",
    "   # pred_y_df=df.dataframe({'Actual value':y_test,'Predicted value':y_pred, 'Difference':y_test-y_pred})\n",
    "   # pred_y_df[0:20]\n",
    "\n",
    "      ## database cloding \n",
    "    mydb.close() #close the connection\n",
    "except Exception as e:\n",
    "    mydb.close()\n",
    "    print(str(e))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
